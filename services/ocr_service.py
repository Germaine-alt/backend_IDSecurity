from typing import List, Dict, Any, Optional
import easyocr
import numpy as np
import json
import os
from rapidfuzz import fuzz
from functools import lru_cache
import logging
from .image_preprocessing import preprocess_for_ocr
from sqlalchemy import select
import re
from sqlalchemy import select
from .text_utils import clean_text_for_matching, contains_digits, normalize_date_str

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

class OCRService:
    def __init__(self, langs: List[str] = None, use_gpu: bool = False):
        langs = langs or ['fr', 'en']
        logger.info("Initialisation EasyOCR...")
        self.reader = easyocr.Reader(langs, gpu=use_gpu)
        logger.info("EasyOCR pr√™t.")
        
    def _load_documents(self, db, DocumentModel):
        logger.info("Chargement des documents (safe mode)...")

        rows = db.session.execute(
            select(
                DocumentModel.id,
                DocumentModel.numero_document,
                DocumentModel.nom,
                DocumentModel.prenom,
                DocumentModel.nationalite,
                DocumentModel.date_de_naissance,
                DocumentModel.date_d_expiration,
                DocumentModel.sexe
            )
        ).all()

        documents = []
        for r in rows:
            documents.append({
                "id": r.id,
                "numero_document": r.numero_document,
                "nom": r.nom,
                "prenom": r.prenom,
                "nationalite": r.nationalite,
                "date_de_naissance": r.date_de_naissance,
                "date_d_expiration": r.date_d_expiration,
                "sexe": r.sexe
            })

        logger.info("Documents charg√©s: %d", len(documents))
        return documents
 
    def process_image(self, image_path: str, preprocess: bool = True) -> List[Dict[str, Any]]:
        """
        Lance le pipeline OCR sur l'image et renvoie une liste de dicts:
        { bbox, text, confidence }
        """
        if preprocess:
            img = preprocess_for_ocr(image_path)
        else:
            import cv2
            img = cv2.imread(image_path)
            if img is None:
                raise FileNotFoundError(image_path)

        
        results = self.reader.readtext(img, detail=1, paragraph=False)

        # normaliser la sortie
        normalized = []
        for bbox, text, conf in results:
            normalized.append({
                "bbox": [[int(p[0]), int(p[1])] for p in bbox],
                "text": text.strip(),
                "confidence": float(conf)
            })
        return normalized

    def annotate_image(self, image_path: str, results: List[Dict[str, Any]], output_dir: str = "public/results") -> str:
        import cv2
        os.makedirs(output_dir, exist_ok=True)
        image = cv2.imread(image_path)
        if image is None:
            raise FileNotFoundError(image_path)

        for res in results:
            pts = np.array(res['bbox'], dtype=np.int32)
            cv2.polylines(image, [pts], True, (0, 255, 0), 2)
            
            x, y = pts[0]
            cv2.putText(image, res['text'], (x, max(y - 6, 10)),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

        out_path = os.path.join(output_dir, f"annotated_{os.path.basename(image_path)}")
        cv2.imwrite(out_path, image)
        return out_path

    def save_result_to_db(self, db, OCRResultModel, filename: str, results: List[Dict[str, Any]], annotated_path: str):
        full_text = " ".join([r["text"] for r in results])
        max_conf = max([r["confidence"] for r in results]) if results else 0.0
        entry = OCRResultModel(
            image_name=filename,
            text_detected=full_text,
            confidence=max_conf,
            bbox=json.dumps(results, ensure_ascii=False),
            annotated_image=annotated_path
        )
        db.session.add(entry)
        db.session.commit()
        return entry

    def fuzzy_match_document(self, text_detected: str, db, DocumentModel, threshold: float = 70.0):
        text_norm = clean_text_for_matching(text_detected)

        docs = self._load_documents(db, DocumentModel)

        fields_weights = {
            "numero_document": 2,
            "nom": 3,
            "prenom": 3,
            "nationalite": 1,
            "date_de_naissance": 1,
            "date_d_expiration": 1
        }

        results = []

        for doc in docs:
            total_score = 0.0
            total_weight = 0.0
            scores_detail = {}

            for field, weight in fields_weights.items():
                val = doc.get(field)
                if not val:
                    continue

                val_norm = clean_text_for_matching(str(val))

                if "date" in field and not contains_digits(text_norm):
                    continue

                score = fuzz.token_set_ratio(text_norm, val_norm)
                scores_detail[field] = score

                total_score += score * weight
                total_weight += weight

            global_score = (total_score / total_weight) if total_weight else 0.0

            if global_score >= threshold:
                results.append({
                    "document_id": doc["id"],
                    "numero_document": doc["numero_document"],
                    "nom": doc["nom"],
                    "prenom": doc["prenom"],
                    "sexe": doc.get("sexe"),
                    "scores_detail": scores_detail,
                    "global_similarity_score": round(global_score, 2)
                })

        results.sort(key=lambda x: x["global_similarity_score"], reverse=True)
        return results













    def extract_externe_fields(self, results):
        """
        Extraction pr√©cise du nom et pr√©nom pour documents externes
        Utilise plusieurs strat√©gies : patterns, positions spatiales, et validation stricte
        """
        nom = None
        prenom = None
        
        # Filtrer les r√©sultats avec faible confiance (< 0.5)
        filtered_results = [r for r in results if r.get("confidence", 0) >= 0.5]
        if not filtered_results:
            filtered_results = results  # Fallback si tous ont faible confiance
        
        # Mots √† ignorer (institutions et titres)
        MOTS_IGNORES = [
            'REPUBLIQUE', 'R√âPUBLIQUE', 'RERUBLIQUE', 'TOGOLAISE', 'TOGO',
            'MINISTERE', 'MINISTRE', 'AINISTERE', 'CHARGE', 'SECURITE', 'S√âCURIT√â',
            'CARTE', 'IDENTITE', 'IDENTIT√â', 'NATIONALE', 'NATIONAL',
            'PASSEPORT', 'PERMIS', 'CONDUIRE', 'DOCUMENT',
            'EXPIRE', 'EXPIRATION', 'VALIDE', 'VALIDITE', 'VALIDIT√â',
            'INTERIEUR', 'INT√âRIEUR', 'NUMERO', 'NUM√âRO', 'SEXE',
            'PROFESSION', 'FAIT', 'SIGNATURE', 'NE', 'N√âE', 'NAME', 'SURNAME',
            'BIRTH', 'DATE', 'BORN', 'NATIONALITY', 'NATIONALIT√â'
        ]
        
        # Labels possibles pour NOM et PRENOM
        NOM_LABELS = [r'N[O√î]M', r'NAME', r'SURNAME', r'FAMILY\s*NAME', r'LAST\s*NAME']
        PRENOM_LABELS = [r'PR[E√â]N[O√î]MS?', r'FIRST\s*NAME', r'GIVEN\s*NAME', r'FORENAME']
        
        # Trier par position verticale (haut -> bas) puis horizontale (gauche -> droite)
        sorted_results = sorted(filtered_results, key=lambda r: (r["bbox"][0][1], r["bbox"][0][0]))
        
        # Combiner tout le texte pour recherche globale
        full_text = " ".join([r["text"] for r in filtered_results])
        full_upper = full_text.upper()
        
        print(f"üîç Texte OCR complet: {full_text[:300]}...")
        print(f"üìä {len(filtered_results)} r√©sultats filtr√©s (confiance >= 0.5)")
        
        def is_valid_name(text, is_nom=True):
            """Valide si un texte est un nom/pr√©nom valide"""
            if not text or len(text.strip()) < 2:
                return False
            
            # Ne doit pas contenir de chiffres
            if re.search(r'\d', text):
                return False
            
            # Ne doit pas √™tre une date
            if re.search(r'\d{1,2}[/\-\.]\d{1,2}[/\-\.]\d{2,4}', text):
                return False
            
            # Ne doit pas contenir de mots interdits
            text_upper = text.upper()
            if any(mot in text_upper for mot in MOTS_IGNORES):
                return False
            
            # Ne doit pas √™tre trop court apr√®s nettoyage
            clean = re.sub(r'[^A-Za-z√Ä-√ø\s\-]', '', text).strip()
            if len(clean) < 2:
                return False
            
            # Pour NOM : g√©n√©ralement en majuscules
            if is_nom:
                # Accepter si majoritairement en majuscules
                upper_count = sum(1 for c in clean if c.isupper())
                if len(clean.replace(' ', '').replace('-', '')) > 0:
                    upper_ratio = upper_count / len(clean.replace(' ', '').replace('-', ''))
                    if upper_ratio < 0.5:  # Moins de 50% en majuscules
                        return False
            
            return True
        
        def extract_after_label(text, label_pattern, is_nom=True):
            """Extrait la valeur apr√®s un label (NOM, PRENOM, etc.)"""
            # Pattern pour capturer le label suivi de : ou espace et la valeur
            patterns = [
                rf'{label_pattern}\s*[:]\s*([A-Za-z√Ä-√ø\s\-]+)',
                rf'{label_pattern}\s+([A-Za-z√Ä-√ø\s\-]+)',
                rf'{label_pattern}\s*[:]\s*([A-Z√Ä-≈∏\s\-]+)',  # Pour NOM en majuscules
            ]
            
            for pattern in patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    candidate = match.group(1).strip()
                    # Nettoyer
                    if is_nom:
                        candidate = re.sub(r'[^A-Z√Ä-≈∏\s\-]', '', candidate.upper()).strip()
                    else:
                        candidate = re.sub(r'[^A-Za-z√Ä-√ø\s\-]', '', candidate).strip()
                    candidate = re.sub(r'\s+', ' ', candidate)
                    
                    if is_valid_name(candidate, is_nom=is_nom):
                        return candidate
            return None
        
        # === STRAT√âGIE 1 : Recherche par patterns globaux am√©lior√©s ===
        for nom_label in NOM_LABELS:
            if not nom:
                candidate = extract_after_label(full_upper, nom_label, is_nom=True)
                if candidate:
                    nom = candidate
                    print(f"‚úÖ Nom trouv√© via pattern global {nom_label}: {nom}")
                    break
        
        for prenom_label in PRENOM_LABELS:
            if not prenom:
                candidate = extract_after_label(full_text, prenom_label, is_nom=False)
                if candidate:
                    prenom = candidate
                    print(f"‚úÖ Pr√©nom trouv√© via pattern global {prenom_label}: {prenom}")
                    break
        
        # === STRAT√âGIE 2 : Recherche ligne par ligne avec positions spatiales ===
        if not nom or not prenom:
            nom_index = None
            prenom_index = None
            
            for i, r in enumerate(sorted_results):
                txt = r["text"].strip()
                upper = txt.upper()
                y_pos = r["bbox"][0][1]  # Position Y (verticale)
                
                # Chercher label NOM
                if not nom:
                    for nom_label in NOM_LABELS:
                        if re.search(nom_label, upper, re.IGNORECASE):
                            nom_index = i
                            # Extraire depuis la m√™me ligne
                            candidate = extract_after_label(txt, nom_label, is_nom=True)
                            if candidate:
                                nom = candidate
                                print(f"‚úÖ Nom trouv√© ligne {i} via label: {nom}")
                                break
                            
                            # Si rien sur la m√™me ligne, chercher ligne suivante
                            if i + 1 < len(sorted_results):
                                next_r = sorted_results[i + 1]
                                next_y = next_r["bbox"][0][1]
                                # V√©rifier que la ligne suivante est proche verticalement (max 50px)
                                if abs(next_y - y_pos) < 50:
                                    next_txt = next_r["text"].strip()
                                    next_clean = re.sub(r'[^A-Z√Ä-≈∏\s\-]', '', next_txt.upper()).strip()
                                    next_clean = re.sub(r'\s+', ' ', next_clean)
                                    if is_valid_name(next_clean, is_nom=True):
                                        nom = next_clean
                                        print(f"‚úÖ Nom trouv√© ligne suivante {i+1}: {nom}")
                                        break
                
                # Chercher label PRENOM
                if not prenom:
                    for prenom_label in PRENOM_LABELS:
                        if re.search(prenom_label, upper, re.IGNORECASE):
                            prenom_index = i
                            # Extraire depuis la m√™me ligne
                            candidate = extract_after_label(txt, prenom_label, is_nom=False)
                            if candidate:
                                prenom = candidate
                                print(f"‚úÖ Pr√©nom trouv√© ligne {i} via label: {prenom}")
                                break
                            
                            # Si rien sur la m√™me ligne, chercher ligne suivante
                            if i + 1 < len(sorted_results):
                                next_r = sorted_results[i + 1]
                                next_y = next_r["bbox"][0][1]
                                # V√©rifier que la ligne suivante est proche verticalement
                                if abs(next_y - y_pos) < 50:
                                    next_txt = next_r["text"].strip()
                                    next_clean = re.sub(r'[^A-Za-z√Ä-√ø\s\-]', '', next_txt).strip()
                                    next_clean = re.sub(r'\s+', ' ', next_clean)
                                    if is_valid_name(next_clean, is_nom=False):
                                        prenom = next_clean
                                        print(f"‚úÖ Pr√©nom trouv√© ligne suivante {i+1}: {prenom}")
                                        break
            
            # Si on a trouv√© NOM mais pas PRENOM (ou vice versa), chercher proche spatialement
            if nom_index is not None and not prenom:
                # Chercher PRENOM pr√®s du NOM (dans les 3 lignes suivantes)
                for i in range(nom_index + 1, min(nom_index + 4, len(sorted_results))):
                    r = sorted_results[i]
                    txt = r["text"].strip()
                    clean = re.sub(r'[^A-Za-z√Ä-√ø\s\-]', '', txt).strip()
                    clean = re.sub(r'\s+', ' ', clean)
                    if is_valid_name(clean, is_nom=False) and len(clean) >= 3:
                        prenom = clean
                        print(f"‚úÖ Pr√©nom trouv√© pr√®s du NOM (ligne {i}): {prenom}")
                        break
            
            if prenom_index is not None and not nom:
                # Chercher NOM pr√®s du PRENOM (dans les 3 lignes pr√©c√©dentes ou suivantes)
                for i in range(max(0, prenom_index - 3), min(prenom_index + 4, len(sorted_results))):
                    if i == prenom_index:
                        continue
                    r = sorted_results[i]
                    txt = r["text"].strip()
                    clean = re.sub(r'[^A-Z√Ä-≈∏\s\-]', '', txt.upper()).strip()
                    clean = re.sub(r'\s+', ' ', clean)
                    if is_valid_name(clean, is_nom=True) and len(clean) >= 3:
                        nom = clean
                        print(f"‚úÖ Nom trouv√© pr√®s du PRENOM (ligne {i}): {nom}")
                        break
        
        # === STRAT√âGIE 3 : D√©tection de format "NOM PRENOM" sur une m√™me ligne ===
        if not nom or not prenom:
            for r in sorted_results:
                txt = r["text"].strip()
                # Pattern pour "NOM PRENOM" ou "NOM, PRENOM" ou "NOM : PRENOM"
                # Chercher deux mots/phrases s√©par√©s
                parts = re.split(r'[,\s:]+', txt)
                if len(parts) >= 2:
                    # Premier √©l√©ment comme NOM potentiel
                    if not nom:
                        candidate_nom = re.sub(r'[^A-Z√Ä-≈∏\s\-]', '', parts[0].upper()).strip()
                        candidate_nom = re.sub(r'\s+', ' ', candidate_nom)
                        if is_valid_name(candidate_nom, is_nom=True) and len(candidate_nom) >= 3:
                            nom = candidate_nom
                            print(f"‚úÖ Nom trouv√© via format combin√©: {nom}")
                    
                    # Deuxi√®me √©l√©ment comme PRENOM potentiel
                    if not prenom and len(parts) >= 2:
                        candidate_prenom = re.sub(r'[^A-Za-z√Ä-√ø\s\-]', '', parts[1]).strip()
                        candidate_prenom = re.sub(r'\s+', ' ', candidate_prenom)
                        if is_valid_name(candidate_prenom, is_nom=False) and len(candidate_prenom) >= 3:
                            prenom = candidate_prenom
                            print(f"‚úÖ Pr√©nom trouv√© via format combin√©: {prenom}")
        
        # === STRAT√âGIE 4 : Heuristique am√©lior√©e (dernier recours) ===
        if not nom or not prenom:
            print("‚ö†Ô∏è Strat√©gie heuristique activ√©e")
            
            # Trier par confiance d√©croissante pour prioriser les r√©sultats fiables
            sorted_by_conf = sorted(filtered_results, key=lambda r: r.get("confidence", 0), reverse=True)
            
            for r in sorted_by_conf:
                txt = r["text"].strip()
                upper = txt.upper()
                clean_upper = re.sub(r'[^A-Z√Ä-≈∏\s\-]', '', upper).strip()
                clean_mixed = re.sub(r'[^A-Za-z√Ä-√ø\s\-]', '', txt).strip()
                
                # NOM : majuscules, pas de chiffres, pas de mots interdits
                if (not nom and 
                    len(clean_upper) >= 3 and 
                    clean_upper.isupper() and
                    is_valid_name(clean_upper, is_nom=True)):
                    nom = clean_upper
                    print(f"‚úÖ Nom heuristique: {nom}")
                
                # PRENOM : casse mixte possible, pas de chiffres
                if (not prenom and 
                    len(clean_mixed) >= 3 and
                    is_valid_name(clean_mixed, is_nom=False)):
                    prenom = clean_mixed
                    print(f"‚úÖ Pr√©nom heuristique: {prenom}")
                
                if nom and prenom:
                    break
        
        # Normaliser les r√©sultats finaux
        if nom:
            nom = ' '.join(nom.split())
            nom = nom.upper()
            # Validation finale
            if not is_valid_name(nom, is_nom=True):
                nom = None
        
        if prenom:
            prenom = ' '.join(prenom.split())
            # Capitaliser proprement (premi√®re lettre de chaque mot)
            prenom = ' '.join(word.capitalize() for word in prenom.split())
            # Validation finale
            if not is_valid_name(prenom, is_nom=False):
                prenom = None
        
        print(f"üìù R√©sultat final - Nom: {nom}, Pr√©nom: {prenom}")
        
        return {
            "nom": nom,
            "prenom": prenom
        }
    

    